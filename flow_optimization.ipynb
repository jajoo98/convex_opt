{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f24a9b6d",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24f3d8",
   "metadata": {},
   "source": [
    "### Optimization Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a8e4c8",
   "metadata": {},
   "source": [
    "Since the cost functions given to us are convex, we can form the objective as a sum of convex functions, which is convex. The constraint on flow conservation at each node is linear in the variables. The inequality constraints are all convex. For now, we frame the problem with a possibly non-linear equality constraint. <br> <br>\n",
    "$min. \\sum_{i=1}^{n} f_{i}\\left(s_{i}\\right)$ <br>\n",
    "$s.t. u_j \\geq 0, v_j \\geq 0, u_j \\geq v_j, j=1 \\ldots m$ <br>\n",
    "&emsp; &ensp; $A^{\\mathrm{in}} v+s=A^{\\mathrm{out}} u$ <br>\n",
    "&emsp; &ensp; $u_j = \\phi(v_j), j=1 \\ldots m$ <br><br>\n",
    "Using the properties of $\\phi$, we can eliminate $u$ entirely from our problem by writing $u = \\phi(v)$. This will ensure that $u \\geq v$ (since $\\phi(v) \\geq v$) and $u \\geq 0$ (since $u \\geq v$ and $v \\geq 0$). This gives us an equivalent problem <br> <br>\n",
    "$min. \\sum_{i=1}^{n} f_{i}\\left(s_{i}\\right)$ <br>\n",
    "$s.t. v \\geq 0$ <br>\n",
    "&emsp; &ensp; $A^{\\mathrm{in}} v+s=A^{\\mathrm{out}} \\phi(v)$ <br> <br>\n",
    "or <br><br>\n",
    "$min. \\sum_{i=1}^{n} f_{i}\\left(s_{i}\\right)$ <br>\n",
    "$s.t. v \\geq 0$ <br>\n",
    "&emsp; &ensp; $A^{\\mathrm{out}}\\phi(v) -A^{\\mathrm{in}} v-s=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5188876f",
   "metadata": {},
   "source": [
    "### First Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9da32",
   "metadata": {},
   "source": [
    "#### The issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dda146a",
   "metadata": {},
   "source": [
    "Clearly, the above formulation is not necessarily a convex optimization problem since we do not know if the function $\\phi$ is linear or not. In the case it is not linear, the equality constraint is not linear and hence breaks the rules of formulation of a convex optimization problem. What we do know is that $\\phi$ is an increasing convex function. We can use this information to augment our problem. Note that we do not use $\\psi$ in our formulation since it's an equivalent constraint. We could include it in our problem formulation as a redundant constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ecd817",
   "metadata": {},
   "source": [
    "#### Handling convex equality constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53734d81",
   "metadata": {},
   "source": [
    "From exercise 4.6 in the textbook, in some special cases it is possible to handle\n",
    "convex equality constraint functions, i.e., constraints of the form h(x) = 0, where h is\n",
    "convex. Suppose we can guarantee that at any optimal solution x*\n",
    "of the convex problem, we have h(x*) = 0, i.e., the inequality h(x) $\\leq$ 0 is always active at the solution.\n",
    "Then we can solve the (nonconvex) problem by solving a convex problem formed by relaxing the equality to an inequality. For the general form optimization problem, the guarantee can be backed by the existence of an index $r$ such that: <br>\n",
    "$f_0$ is monotonically increasing in $x_r$ <br>\n",
    "$f_1,\\ldots , f_m$ are nondecreasing in $x_r$ <br>\n",
    "$h$ is monotonically decreasing in $x_r$. <br>\n",
    "In our case, with the problem variables as $s$ and $v$ and $h = A^{\\mathrm{out}}\\phi(v) -A^{\\mathrm{in}} v-s$, we select any $s_i$ as $x_r$. It is given to us that $f_i$ are nondecreasing (this is fine too as it means that in the case of $h(x)<0$, we could find, at worst, a point with $h(x)=0$ having the same objective value by decreasing $s_i$) so the first point holds. The second point hold vaccuously. The third point is clear from our definition of $h$ i.e. $h$ is in fact monotonically decreasing in $s$. In conclusion, we can guarantee that the equality constraint relaxed to an inequality will hold tightly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659640c9",
   "metadata": {},
   "source": [
    "#### Relaxing the equality constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a8f4d",
   "metadata": {},
   "source": [
    "This leads to us to a new problem formulation with a convex inequality constraint. Now the objective is convex and the inequality constraints are also convex. Therefore, it is a convex optimization problem. The formulation is <br> <br>\n",
    "$min. \\sum_{i=1}^{n} f_{i}\\left(s_{i}\\right)$ <br>\n",
    "$s.t. v \\geq 0$ <br>\n",
    "&emsp; &ensp; $A^{\\mathrm{out}}\\phi(v) -A^{\\mathrm{in}} v-s \\leq 0$ <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5027a8c",
   "metadata": {},
   "source": [
    "#### Making sense of the relaxation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d375e01",
   "metadata": {},
   "source": [
    "Since the objective function is nondecreasing in $s$, it makes intuitive sense that the inequality constraint will hold with tight equality. If we find a point with the inequality constraint not holding tightly, we could always decrease $s$ till it holds tightly, decreasing (rather, not increasing) the objective value at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7df5ed3",
   "metadata": {},
   "source": [
    "### Alternative Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0783b2",
   "metadata": {},
   "source": [
    "We have the problem <br>\n",
    "$min. \\sum_{i=1}^{n} f_{i}\\left(s_{i}\\right)$ <br>\n",
    "$s.t. v \\geq 0$ <br>\n",
    "&emsp; &ensp; $A^{\\mathrm{out}}\\phi(v) -A^{\\mathrm{in}} v-s=0$ <br>\n",
    "So if we define $s_i = (A^{\\mathrm{out}}\\phi(v) -A^{\\mathrm{in}} v)_i$, we can simply reformulate the problem as <br>\n",
    "$min. \\sum_{i=1}^{n} f_{i}((A^{\\mathrm{out}}\\phi(v) -A^{\\mathrm{in}} v)_i)$ <br>\n",
    "s.t. $v \\geq 0$ <br>\n",
    "Now we can use the composition rules to see that our objective is convex. The composition rules for $f(x) = h(g(x))$ being convex are $g$ convex, $h$ convex, $\\tilde{h}$ nondecreasing. In our formulation, we have $\\phi$ as convex so the inner function is convex in $v$. $f_i$ are given to be convex and their extended value extenstions are infact nondecreasing. Hence our entire objective function is a sum of convex functions which is convex. The inequality constraint is obviously convex so the entire problem is a convex optimization problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf5359c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cvxpy_env]",
   "language": "python",
   "name": "conda-env-cvxpy_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
